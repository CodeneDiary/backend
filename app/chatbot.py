from fastapi import APIRouter, UploadFile, File, Form, Request, Depends
from fastapi.responses import FileResponse, JSONResponse
from sqlalchemy.orm import Session
from datetime import datetime
import openai
import os
import tempfile
import json
import uuid
from dotenv import load_dotenv
from google.cloud import speech, texttospeech
from pydub import AudioSegment
from app.model import Diary, ConversationLog  #  ConversationLog ëª¨ë¸ ì¶”ê°€
#from app.main import get_db
from app.deps import get_db
import base64
from google.oauth2 import service_account

router = APIRouter()

# í™˜ê²½ ë³€ìˆ˜
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")
# GOOGLE_STT_KEY_PATH = os.getenv("GOOGLE_STT_KEY_PATH")
# if GOOGLE_STT_KEY_PATH:
#     os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = GOOGLE_STT_KEY_PATH

# AUDIO_DIR = "generated_audio"
# os.makedirs(AUDIO_DIR, exist_ok=True)

# STT ì²˜ë¦¬ë¥¼ ìœ„í•´ m4a â†’ flac íŒŒì¼ ë³€í™˜
def convert_m4a_to_flac(input_path):
    sound = AudioSegment.from_file(input_path, format="m4a")
    flac_path = input_path.replace(".m4a", ".flac")
    sound.export(flac_path, format="flac")
    return flac_path

# ì‚¬ìš©ì ì…ë ¥ì— íŠ¹ì • í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ê°ì • ëª¨ë“œ(T/F)ë¥¼ íŒë‹¨
def detect_mode(user_input, prev_mode="F"):
    user_input = user_input.lower()
    if any(k in user_input for k in ["ì´ì„±ì ìœ¼ë¡œ", "ë…¼ë¦¬ì ìœ¼ë¡œ", "ëƒ‰ì •í•˜ê²Œ"]):
        return "T"
    elif any(k in user_input for k in ["ê³µê°", "ê°ì„±ì ìœ¼ë¡œ", "ìœ„ë¡œ"]):
        return "F"
    return prev_mode

# GPT ë©”ì‹œì§€ ìƒì„±
def build_messages(history, user_input, mode):
    messages = [
        {
            "role": "system",
            "content": (
                "ë‹¹ì‹ ì€ ê°ì • ìƒë‹´ì„ í•´ì£¼ëŠ” ë”°ëœ»í•œ ì±—ë´‡ì…ë‹ˆë‹¤. "
                "ì‚¬ìš©ìì˜ ê°ì •ì„ ì´í•´í•˜ê³  ìš”ì²­í•œ ìŠ¤íƒ€ì¼ì— ë”°ë¼ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤. "
                "T: ì´ì„±ì  ì¡°ì–¸ / F: ê°ì„±ì  ê³µê°. "
                "ë¬´ì¡°ê±´ ë¶€ë“œëŸ¬ìš´ ì–´ì¡°ë¥¼ ìœ ì§€í•˜ì„¸ìš”."
            )
        }
    ]
    for turn in history:
        messages.append({"role": "user", "content": turn["user_input"]})
        messages.append({"role": "assistant", "content": turn["response"]})
    prompt = f"[ìš”ì²­ ìŠ¤íƒ€ì¼: {mode}]\n{user_input}"
    messages.append({"role": "user", "content": prompt})
    return messages

# ì±—ë´‡ ì‘ë‹µ ìƒì„±
def get_gpt_response(messages):
    client = openai.OpenAI()
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=0.7,
        max_tokens=300,
    )
    return response.choices[0].message.content.strip()

# Google TTS APIë¥¼ í™œìš©í•´ GPT ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ mp3 ìŒì„±ìœ¼ë¡œ ë³€í™˜


def synthesize_speech_base64(text: str) -> str:
    try:
        #ì§ì ‘ ê²½ë¡œ ì§€ì •
        credentials = service_account.Credentials.from_service_account_file(
            "./leafy-computing-460314-v0-c752836719ce.json"
        )

        client = texttospeech.TextToSpeechClient(credentials=credentials)

        synthesis_input = texttospeech.SynthesisInput(text=text)
        voice = texttospeech.VoiceSelectionParams(
            language_code="ko-KR",
            ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL,
        )
        audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)

        response = client.synthesize_speech(
            input=synthesis_input, voice=voice, audio_config=audio_config
        )

        audio_base64 = base64.b64encode(response.audio_content).decode("utf-8")
        return audio_base64

    except Exception as e:
        print("âŒ TTS ë³€í™˜ ì˜¤ë¥˜:", e)
        raise RuntimeError(f"TTS ë³€í™˜ ì‹¤íŒ¨: {str(e)}")


# ëŒ€í™” ë‚´ì—­ì„ ConversationLog í…Œì´ë¸”ì— ì €ì¥
def save_chat_log_db(db: Session, diary_id: int, user_input: str, response: str, mode: str, audio_url: str = None):
    log = ConversationLog(
        diary_id=diary_id,
        user_input=user_input,
        response=response,
        mode=mode,
        audio_url=audio_url
    )
    db.add(log)
    db.commit()

# ì¼ê¸° í…ìŠ¤íŠ¸ ì¡°íšŒ
# @router.get("/diary/text/{diary_id}")
# async def get_diary_text(diary_id: int, db: Session = Depends(get_db)):
#     diary = db.query(Diary).filter(Diary.id == diary_id).first()
#     if not diary:
#         return JSONResponse(status_code=404, content={"error": "ì¼ê¸° ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."})
#     return {
#         "text": {
#             "id": diary.id,
#             "content": diary.content,
#             "emotion": diary.emotion,
#             "confidence": diary.confidence,
#             "date": diary.date
#         }
#     }

# í”„ë¡ íŠ¸ì—ì„œ diary_idë¥¼ ì „ë‹¬í•˜ë©´ í•´ë‹¹ ì¼ê¸° ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì²« ì§ˆë¬¸ ìƒì„± í›„ ì§ˆë¬¸ TTS ë³€í™˜ í›„ ì˜¤ë””ì˜¤ ì €ì¥
@router.post("/generate-question")
async def generate_question(request: Request, db: Session = Depends(get_db)):
    try:
        body = await request.json()
        diary_id = body.get("diary_id")

        if not diary_id:
            return JSONResponse(status_code=400, content={"error": "diary_id is required"})

        diary = db.query(Diary).filter(Diary.id == int(diary_id)).first()
        if not diary:
            return JSONResponse(status_code=404, content={"error": "ì¼ê¸° ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."})

        diary_content = diary.content
        #print("ğŸ“– ì¼ê¸° ë‚´ìš©:", diary_content)

        messages = [
            {
                "role": "system",
                "content": (
                    "ë‹¹ì‹ ì€ ê°ì • ìƒë‹´ ì±—ë´‡ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì‘ì„±í•œ ì¼ê¸° ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ê°ì •ì„ ë” ì˜ íŒŒì•…í•  ìˆ˜ ìˆëŠ” ì²« ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”. "
                    "ì§ˆë¬¸ì€ ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ í•˜ê³ , ê°ì •ì„ ìœ ë„í•˜ëŠ” ë¶€ë“œëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ì‹œì‘í•˜ì„¸ìš”."
                )
            },
            {"role": "user", "content": f"ì¼ê¸° ë‚´ìš©: {diary_content}"}
        ]

        try:
            client = openai.OpenAI()
            completion = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                temperature=0.7,
                max_tokens=300,
            )
            question = completion.choices[0].message.content.strip()
            #print("ğŸ§  ìƒì„±ëœ ì§ˆë¬¸:", question)
        except Exception as gpt_error:
            #print("âŒ GPT ì‘ë‹µ ì‹¤íŒ¨:", gpt_error)
            return JSONResponse(status_code=500, content={"error": "GPT ì‘ë‹µ ì‹¤íŒ¨"})

        # TTSë¡œ ë³€í™˜
        try:
            # TTS â†’ base64
            audio_base64 = synthesize_speech_base64(question)

        except Exception as tts_error:
            #print("âŒ TTS ë³€í™˜ ì‹¤íŒ¨:", tts_error)
            return JSONResponse(status_code=500, content={"error": "TTS ë³€í™˜ ì‹¤íŒ¨~"})

        return {
            "question": question,
            "audio_base64": audio_base64
        }

    except Exception as e:
        #print("âŒ ìµœìƒìœ„ ì—ëŸ¬:", e)
        return JSONResponse(status_code=500, content={"error": "ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨"})



# ìŒì„± ì—…ë¡œë“œ ë° ëŒ€í™” ì²˜ë¦¬
@router.post("/upload")
async def upload_audio(
    file: UploadFile = File(...),
    history: str = Form(...),
    diary_id: str = Form(...),
    db: Session = Depends(get_db)
):
    history_data = json.loads(history)
    with tempfile.NamedTemporaryFile(delete=False, suffix=".m4a") as tmp:
        tmp.write(await file.read())
        m4a_path = tmp.name

    flac_path = convert_m4a_to_flac(m4a_path)
    client = speech.SpeechClient()
    with open(flac_path, "rb") as audio_file:
        content = audio_file.read()

    audio = speech.RecognitionAudio(content=content)
    config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.FLAC,
        sample_rate_hertz=16000,
        language_code="ko-KR"
    )
    stt_result = client.recognize(config=config, audio=audio)
    user_input = " ".join([r.alternatives[0].transcript for r in stt_result.results])

    prev_mode = history_data[-1].get("mode", "F") if history_data else "F"
    mode = detect_mode(user_input, prev_mode)

    messages = build_messages(history_data, user_input, mode)
    response_text = get_gpt_response(messages)

    # TTS â†’ base64
    audio_base64 = synthesize_speech_base64(response_text)

    # DB ì €ì¥
    save_chat_log_db(
        db=db,
        diary_id=int(diary_id),
        user_input=user_input,
        response=response_text,
        mode=mode,
        #audio_url=None  # URL ì €ì¥ ì•ˆ í•¨
    )

    return {
        "input": user_input,
        "response": response_text,
        "audio_base64": audio_base64
    }


# # ì˜¤ë””ì˜¤ íŒŒì¼ ë°˜í™˜
# @router.get("/audio/{filename}")
# async def get_audio(filename: str):
#     path = os.path.join(AUDIO_DIR, filename)
#     if os.path.exists(path):
#         return FileResponse(path, media_type="audio/mpeg")
#     return {"error": "íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."}

# ëŒ€í™” ê¸°ë¡ ì¡°íšŒ (DB ê¸°ë°˜)
@router.get("/chat-history")
async def get_chat_history(diary_id: int, db: Session = Depends(get_db)):
    logs = (
        db.query(ConversationLog)
        .filter(ConversationLog.diary_id == diary_id)
        .order_by(ConversationLog.created_at)
        .all()
    )

    result = [
        {
            "user_input": log.user_input,
            "response": log.response,
            "mode": log.mode,
            #"audio_url": log.audio_url,
            "created_at": log.created_at.isoformat()
        }
        for log in logs
    ]
    return {"logs": result}
